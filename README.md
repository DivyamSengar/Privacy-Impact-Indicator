# Privacy Impact Indicator (CSEÂ 291 Final Project)

**Author:** Divyamâ€¯Sengar Â |Â  **Version:**â€¯1.0.0Â Â·Â JuneÂ 2025

A ChromeÂ ManifestÂ V3 extension that turns lowâ€‘level network telemetry into an **ambient 0â€“100 privacy score**.  Think of it as a *privacy speedometer*: the badge glows green on trackerâ€‘light sites and slides toward red as hidden requests increase.

---


## ğŸš€ QuickÂ Start

1. **Clone & install**

   ```bash
   git clone https://github.com/divyamsengar/privacy-impact-indicator.git
   cd privacy-impact-indicator
   ```
2. **Load in Chrome**
   â€¢ Visit `chrome://extensions`
   â€¢ Enable *Developer mode*
   â€¢ Click **Load unpacked** â†’ select the `extension/` folder
3. **Browse the web** â€“ a 64â€‘pixel badge appears bottomâ€‘right.  Redâ€¯â‰¤â€¯40, Yellowâ€¯41â€“69, Greenâ€¯â‰¥â€¯70.
4. **Click the badge** to open the slideâ€‘in panel (secondâ€‘byâ€‘second trace + worstâ€‘seen anchor).

---

## ğŸ”¬ How the Score Works

RiskÂ =Â $100\,Â·(1 - e^{-(0.45Â·t + 0.15Â·h)})$
`t`Â = tracker requests (from a 40â€¯662â€‘domain DuckDuckGoÂ +Â Disconnect list)
`h`Â = distinct thirdâ€‘party eTLD+1 hosts
The extension samples continuously but **publishes a 5â€‘second EMA** to avoid sensory overload.

---

## ğŸ—‚ Repo layout

| Path                | Whatâ€™s inside                                                                 |
| ------------------- | ----------------------------------------------------------------------------- |
| **extension/**      | MV3 code: `background.js`, `contentScript.js`, popâ€‘up UI, `trackerList.json`. |
| **analysis/**       | Python helpers â†’ `aggregate_study.py`, `validate_metric.py`, plotting.        |
| **validation/**     | `results.csv` (100â€‘URL crawl) + `roc_curve.png`.                              |
| **data/study.csv** | Anonymised participant metrics (NÂ =Â 15).                                      


---

## ğŸ“Š Reproduce the Study

```bash
# aggregate perâ€‘task CSV exports â†’ study_data.csv
python analysis/aggregate_study.py exports/*.csv

# compute AUROC + Spearman Ï on the 100â€‘URL corpus
python analysis/validate_metric.py
```

Expected:

```
Spearman Ï = -0.81   (pâ‰ˆ2.6eâ€‘24)
AUROC     = 0.91
```
